{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "collapsed_sections": [
        "Yn2lCLC00ZOV",
        "KZIGLD4y0idi"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cy643/generative_ai/blob/main/0429_hw10/0429_hw10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0429_HW10 æ‰“é€ è‡ªå·±çš„åœ–åƒç”ŸæˆWeb App\n",
        "\n",
        "## é¸ç”¨æ¨¡å‹ danbrown/RevAnimated-v1-2-2\n",
        "https://huggingface.co/danbrown/RevAnimated-v1-2-2\n",
        "\n",
        "## Prompt\n",
        "1. A portrait of a beautiful young woman\n",
        "\n",
        "2. A cyberpunk ninja warrior with glowing red cybernetic implants, sleek black armor, dual energy katanas, standing in neon-lit alley, rain and fog, futuristic Tokyo  \n",
        "\n",
        "3. A majestic ice dragon standing on a frozen cliff, glowing blue scales, white flowing hair, piercing crystal eyes, fantasy armor made of frost, snowy background\n",
        "\n",
        "4. A steampunk automaton warrior with exposed brass pistons, glowing furnace chest, spiked pauldrons, mechanical limbs, standing in a smoke-filled factory, industrial background"
      ],
      "metadata": {
        "id": "YdVglWFsIKNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. å®‰è£å¿…è¦å¥—ä»¶"
      ],
      "metadata": {
        "id": "Yn2lCLC00ZOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate safetensors huggingface_hub gradio --upgrade"
      ],
      "metadata": {
        "id": "RbQso1-V3jEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline, UniPCMultistepScheduler\n",
        "import torch\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "import random"
      ],
      "metadata": {
        "id": "Uv6Qa39q0gAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¬ä¸€éœ€è¦ HuggingFace Token æ™‚è«‹é€™æ¨£åš"
      ],
      "metadata": {
        "id": "uTAQrntqQufd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import login\n",
        "# from google.colab import userdata\n",
        "#\n",
        "# hf_token = userdata.get('HuggingFace')\n",
        "# login(token=hf_token)"
      ],
      "metadata": {
        "id": "qYDkE1CnpVvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. è®€å…¥æ¨¡å‹"
      ],
      "metadata": {
        "id": "KZIGLD4y0idi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"danbrown/RevAnimated-v1-2-2\""
      ],
      "metadata": {
        "id": "2Lr8hGzggROl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16\n",
        "    # revision=\"fp16\",  # for SD 1.5 and 2.1\n",
        "    # use_safetensors=True\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "id": "K5I-aj2Zln-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)"
      ],
      "metadata": {
        "id": "34ZC_Zsuiytr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. ç”Ÿæˆçš„å‡½å¼"
      ],
      "metadata": {
        "id": "oGpMA5u2UYHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(prompt, use_enhance, enhance_text, use_negative, negative_text,\n",
        "                    use_custom_seed, custom_seed, height, width, steps, num_images):\n",
        "\n",
        "    height = int(height)\n",
        "    width = int(width)\n",
        "\n",
        "    if height % 8 != 0 or width % 8 != 0:\n",
        "        raise ValueError(\"é«˜åº¦å’Œå¯¬åº¦å¿…é ˆæ˜¯8çš„å€æ•¸ï¼\")\n",
        "\n",
        "    if use_custom_seed:\n",
        "        base_seed = int(custom_seed)\n",
        "    else:\n",
        "        base_seed = random.randint(0, 2**32 - 1)\n",
        "\n",
        "    seeds = [base_seed + i for i in range(num_images)]\n",
        "\n",
        "    prompts = []\n",
        "    negative_prompts = []\n",
        "    generators = []\n",
        "\n",
        "    final_prompt = prompt\n",
        "    if use_enhance and enhance_text:\n",
        "        final_prompt = prompt + \", \" + enhance_text\n",
        "\n",
        "    final_negative = negative_text if use_negative else None\n",
        "\n",
        "    for seed in seeds:\n",
        "        g = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "        generators.append(g)\n",
        "        prompts.append(final_prompt)\n",
        "        negative_prompts.append(final_negative)\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    images = []\n",
        "    for i in range(num_images):\n",
        "        with torch.no_grad():\n",
        "            image = pipe(\n",
        "                prompt=prompts[i],\n",
        "                negative_prompt=negative_prompts[i] if final_negative else None,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                num_inference_steps=steps,\n",
        "                guidance_scale=7.5,\n",
        "                generator=generators[i]\n",
        "            ).images[0]\n",
        "            images.append(image)\n",
        "\n",
        "    return images, f\"ä½¿ç”¨çš„ random seeds: {seeds}\""
      ],
      "metadata": {
        "id": "zuIfG1bEgUMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. æ‰“é€  Gradio Web App"
      ],
      "metadata": {
        "id": "TLXztas3jB2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_enhance = \"masterpiece, ultra high quality, intricate skin details, cinematic lighting, soft lighting, 85mm lens, shallow depth of field, cinematic color grading\"\n",
        "default_negative = \"bad anatomy, blurry, disfigured, poorly drawn hands, extra fingers, mutated hands, low quality, worst quality\"\n",
        "\n",
        "with gr.Blocks(css=\".gradio-container {background-color: #FAFAFA; padding: 20px;} .gr-button {font-size: 18px; background: linear-gradient(to right, #667eea, #764ba2); color: white;}\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ¨ RevAnimated äº’å‹•åœ–åƒç”Ÿæˆå™¨\n",
        "    æ­¡è¿ä½¿ç”¨ï¼è¼¸å…¥æç¤ºè©ã€é¸æ“‡è¨­å®šï¼Œç«‹å³ç”Ÿæˆä½ çš„éŠæˆ²é¢¨æ ¼ä½œå“ï¼\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=6):\n",
        "            prompt = gr.Textbox(label=\"Prompt\", placeholder=\"è«‹è¼¸å…¥ä½ çš„æç¤ºè© (prompt)\", lines=3)\n",
        "            with gr.Row():\n",
        "                use_enhance = gr.Checkbox(label=\"åŠ å¼· Prompt\", value=True)\n",
        "                enhance_text = gr.Textbox(label=\"åŠ å¼·å…§å®¹\", value=default_enhance)\n",
        "            with gr.Row():\n",
        "                use_negative = gr.Checkbox(label=\"ä½¿ç”¨ Negative Prompt\", value=True)\n",
        "                negative_text = gr.Textbox(label=\"Negative Prompt å…§å®¹\", value=default_negative)\n",
        "            with gr.Row():\n",
        "                use_custom_seed = gr.Checkbox(label=\"è‡ªè¨‚ Random Seed\", value=False)\n",
        "                custom_seed = gr.Number(label=\"æŒ‡å®š seed (é¸å¡«)\", value=42)\n",
        "            with gr.Row():\n",
        "                height = gr.Dropdown([\"512\", \"768\", \"1024\"], label=\"é«˜åº¦ Height\", value=\"512\")\n",
        "                width = gr.Dropdown([\"512\", \"768\", \"1024\"], label=\"å¯¬åº¦ Width\", value=\"512\")\n",
        "            with gr.Row():\n",
        "                steps = gr.Slider(10, 50, value=20, step=5, label=\"ç”Ÿæˆæ­¥æ•¸ (Steps)\")\n",
        "                num_images = gr.Slider(1, 4, step=1, value=1, label=\"ç”Ÿæˆå¼µæ•¸\")\n",
        "            generate_btn = gr.Button(\"ğŸš€ é–‹å§‹ç”Ÿæˆï¼\")\n",
        "\n",
        "        with gr.Column(scale=6):\n",
        "            gallery = gr.Gallery(label=\"ç”Ÿæˆçµæœ\", columns=2, object_fit=\"contain\", height=\"auto\")\n",
        "            seed_info = gr.Label(label=\"ä½¿ç”¨çš„ Random Seeds\")\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=generate_images,\n",
        "        inputs=[prompt, use_enhance, enhance_text, use_negative, negative_text,\n",
        "                use_custom_seed, custom_seed, height, width, steps, num_images],\n",
        "        outputs=[gallery, seed_info]\n",
        "    )"
      ],
      "metadata": {
        "id": "bE4m42oMjBTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "a9gcTEvQly7d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}